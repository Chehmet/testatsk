{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f659764",
   "metadata": {},
   "source": [
    "Берём строку без пробелов и пробуем на каждом её начале понять, что это за кусок: целое число, английское слово, или русское слово из словаря pymorphy2.\n",
    "\n",
    "Из всех вариантов разбиения выбираем тот, где сумма квадратов длин кусочков максимальна, то есть длинные осмысленные куски.\n",
    "\n",
    "Где добавляем границы:\n",
    "- Между кириллицей и латиницей\n",
    "\n",
    "- Между буквой и цифрой и наоборот\n",
    "\n",
    "- Между строчной и заглавной\n",
    "\n",
    "Еще я учитываю базовые правила пунктуации: не ставлю пробел перед , . ! ? : ; … % ) ] } » и после ( [ { «. \n",
    "В остальных местах пробел ставится после знака, а не до него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7556452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\chulpan\\miniconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru in c:\\users\\chulpan\\miniconda3\\lib\\site-packages (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\chulpan\\miniconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\chulpan\\miniconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2 pymorphy2-dicts-ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29871a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import lru_cache\n",
    "import inspect\n",
    "from collections import namedtuple\n",
    "\n",
    "if not hasattr(inspect, \"getargspec\"):\n",
    "    \"\"\" Просто имитация inspect.getargspec, чтобы не ругался pymorphy2\"\"\"\n",
    "    FullArgSpec = inspect.getfullargspec\n",
    "    def getargspec(func):\n",
    "        fs = FullArgSpec(func)\n",
    "        ArgSpec = namedtuple(\"ArgSpec\", \"args varargs keywords defaults\")\n",
    "        return ArgSpec(fs.args, fs.varargs, fs.varkw, fs.defaults)\n",
    "    inspect.getargspec = getargspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a14d64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "# Регулярки для определения киррилических и латинских букв\n",
    "_cyr_pat = re.compile(r\"^[А-Яа-яЁё]+$\")\n",
    "_lat_pat = re.compile(r\"^[A-Za-z]+$\")\n",
    "\n",
    "def is_cyrillic(s: str) -> bool:\n",
    "    \"\"\"True, если строка состоит только из кириллических букв\"\"\"\n",
    "    return bool(_cyr_pat.fullmatch(s))\n",
    "\n",
    "def is_latin(s: str) -> bool:\n",
    "    \"\"\"True, если строка состоит только из латинских букв\"\"\"\n",
    "    return bool(_lat_pat.fullmatch(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0282d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделители внутри числа и знаки препинания (минус, тире, дефис, так как тире знак препинания, а дефис может быть частью слова нет)\n",
    "NUM_SEPS = {\",\", \".\", \"'\", \"’\", \"\\u202F\", \"\\u00A0\", \"\\u2009\"}\n",
    "MINUS_SIGNS = {\"-\", \"−\"}\n",
    "\n",
    "def check_number(s: str, start: int = 0) -> int:\n",
    "    \"\"\"\n",
    "    Возвращаем индекс конца числа, начиная с start. \n",
    "    Число может содержать разделители из NUM_SEPS \n",
    "    и начинаться с минуса из MINUS_SIGNS.\n",
    "    Если числа нет, возвращаем start.\n",
    "    \"\"\"\n",
    "    i = start\n",
    "    if i < len(s) and (s[i] in MINUS_SIGNS or s[i] == \"+\"):\n",
    "        i += 1\n",
    "    if i >= len(s) or not s[i].isdigit():\n",
    "        return start\n",
    "    last_separated = False\n",
    "    while i < len(s):\n",
    "        ch = s[i]\n",
    "        if ch.isdigit():\n",
    "            last_separated = False\n",
    "            i += 1\n",
    "        elif ch in NUM_SEPS:\n",
    "            if last_separated: # подряд не может быть два разделителя\n",
    "                break\n",
    "            last_separated = True\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    # Число не должно заканчиваться на разделитель\n",
    "    while i > start and not s[i - 1].isdigit():\n",
    "        i -= 1\n",
    "    return i\n",
    "\n",
    "def check_latin(s: str, start: int = 0) -> int:\n",
    "    \"\"\"Идём вперёд, пока буквы латинские \n",
    "    и возвращаем индекс первого не-латинского символа.\"\"\"\n",
    "    i = start\n",
    "    while i < len(s) and s[i].isalpha() and is_latin(s[i]):\n",
    "        i += 1\n",
    "    return i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "778eb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перед этими символами не должно быть пробела\n",
    "PUNCT = set(\",.;:!?…%)]}»\")\n",
    "B_PUNCT  = set(\"([«\")\n",
    "\n",
    "class NorvigSegmenter:\n",
    "    \"\"\"\n",
    "    Пытаемся разложить вход на осмысленные токены (числа, латинские слова, русские слова из pymorphy2) так, \n",
    "    чтобы максимизировать сумму квадратов длин токенов. Кэшируем, чтобы быстрее было.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_word_len: int = 32):\n",
    "        # Инициализируем морф-анализатора и доступа к DAWG слов\n",
    "        self.morph = pymorphy2.MorphAnalyzer()\n",
    "        self.words_dawg = self.morph.dictionary.words\n",
    "        self.max_word_len = max_word_len\n",
    "        try:\n",
    "            self.segment_recursive.cache_clear()  # очищаем кэш, если он был\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def segment_recursive(self, text: str):\n",
    "        \"\"\"\n",
    "        Рекурсивно бьёт text на токены и максимизирует сумму квадратов длин токенов.\n",
    "        Возвращает (score, tokens).\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return 0.0, []\n",
    "\n",
    "        candidates = []\n",
    "\n",
    "        # 1) Если начинается с цифры — берем число полностью\n",
    "        if text[0].isdigit() or (text[0] in MINUS_SIGNS or text[0] == \"+\"):\n",
    "            j = check_number(text, 0)\n",
    "            if j > 0:\n",
    "                tok = text[:j]\n",
    "                score_rest, rest = self.segment_recursive(text[j:])\n",
    "                candidates.append((len(tok) ** 2 + score_rest, [tok] + rest))\n",
    "\n",
    "        # 2) Если начинается с латинской буквы — берем слово полностью\n",
    "        if text[0].isalpha() and is_latin(text[0]):\n",
    "            j = check_latin(text, 0)\n",
    "            if j > 0:\n",
    "                tok = text[:j]\n",
    "                score_rest, rest = self.segment_recursive(text[j:])\n",
    "                candidates.append((len(tok) ** 2 + score_rest, [tok] + rest))\n",
    "\n",
    "        # 3) Ищем русские слова в DAWG\n",
    "        max_len = min(len(text), self.max_word_len)\n",
    "        for i in range(1, max_len + 1):\n",
    "            w = text[:i]\n",
    "            if w in self.words_dawg:\n",
    "                score_rest, rest = self.segment_recursive(text[i:])\n",
    "                candidates.append((len(w) ** 2 + score_rest, [w] + rest))\n",
    "\n",
    "        # 4) Если ничего не подошло — берём первый символ как отдельный токен\n",
    "        if not candidates:\n",
    "            score_rest, rest = self.segment_recursive(text[1:])\n",
    "            return score_rest, [text[0]] + rest\n",
    "\n",
    "        return max(candidates)\n",
    "\n",
    "    def segment(self, text: str):\n",
    "        \"\"\"\n",
    "        Возвращает множество позиций-границ, где нужно ставить пробелы.\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        _, words = self.segment_recursive(text)\n",
    "\n",
    "        # Склеиваем подряд идущие одиночные кириллические буквы в слова\n",
    "        final_tokens, buf = [], \"\"\n",
    "        for w in words:\n",
    "            if len(w) == 1 and is_cyrillic(w):\n",
    "                buf += w\n",
    "            else:\n",
    "                if buf:\n",
    "                    final_tokens.append(buf)\n",
    "                    buf = \"\"\n",
    "                final_tokens.append(w)\n",
    "        if buf:\n",
    "            final_tokens.append(buf)\n",
    "\n",
    "        # Определяем границы между токенами\n",
    "        positions = set()\n",
    "        cur = 0\n",
    "        for i in range(len(final_tokens) - 1):\n",
    "            left = final_tokens[i]\n",
    "            right = final_tokens[i + 1]\n",
    "            lch, rch = left[-1], right[0]\n",
    "\n",
    "            if rch in PUNCT:\n",
    "                pass\n",
    "            elif lch in B_PUNCT:\n",
    "                pass\n",
    "            elif (len(left) == 1 and not left.isalnum() and\n",
    "                  len(right) == 1 and not right.isalnum()):\n",
    "                pass\n",
    "            else:\n",
    "                positions.add(cur + len(left))\n",
    "\n",
    "            cur += len(left)\n",
    "        return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea13abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'куплюдом' -> [5]\n",
      "'Продамкрышудёшево123' -> [6, 11, 17]\n",
      "'самыйniceфенDyson' -> [5, 9, 12]\n"
     ]
    }
   ],
   "source": [
    "def predict_spaces(text: str, segmenter: NorvigSegmenter) -> str:\n",
    "    \"\"\"\n",
    "    Возвращает строку вида \"[i, j, ...]\" — индексы пробелов.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"[]\"\n",
    "    \n",
    "    algo_pos = segmenter.segment(text)\n",
    "\n",
    "    # Эвристики: кириллица↔латиница, буква↔цифра, цифра↔буква, lower→Upper\n",
    "    heur_pos = set()\n",
    "    for i in range(len(text) - 1):\n",
    "        c, n = text[i], text[i + 1]\n",
    "        is_cyr_c = is_cyrillic(c.lower())\n",
    "        is_cyr_n = is_cyrillic(n.lower())\n",
    "        is_lat_c = is_latin(c.lower())\n",
    "        is_lat_n = is_latin(n.lower())\n",
    "\n",
    "        if (\n",
    "            (c.isalpha() and n.isalpha() and ((is_cyr_c and is_lat_n) or (is_lat_c and is_cyr_n))) or\n",
    "            (c.isalpha() and n.isdigit()) or\n",
    "            (c.isdigit() and n.isalpha()) or\n",
    "            (c.islower() and n.isupper())\n",
    "        ):\n",
    "            heur_pos.add(i + 1)\n",
    "\n",
    "    final_pos = sorted(algo_pos.union(heur_pos))\n",
    "    return \"[]\" if not final_pos else f\"[{', '.join(map(str, final_pos))}]\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seg = NorvigSegmenter()\n",
    "\n",
    "    samples = [\n",
    "        \"куплюдом\",\n",
    "        \"Продамкрышудёшево123\",\n",
    "        \"самыйniceфенDyson\"\n",
    "    ]\n",
    "    for s in samples:\n",
    "        print(f\"{s!r} -> {predict_spaces(s, seg)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1106656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cell5] head:\n",
      "    id                 text_no_spaces  predicted_positions\n",
      "0   0                куплюайфон14про          [5, 10, 12]\n",
      "1   1             ищудомвПодмосковье            [3, 6, 7]\n",
      "2   2  сдаюквартирусмебельюитехникой  [4, 12, 13, 20, 21]\n",
      "3   3     новыйдивандоставканедорого          [5, 10, 18]\n",
      "4   4                отдамдаромкошку              [5, 10]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_PATH  = \"dataset_1937770_3.txt\" \n",
    "OUTPUT_PATH = \"submission.csv\"\n",
    "\n",
    "seg = NorvigSegmenter()\n",
    "p = Path(INPUT_PATH)\n",
    "\n",
    "if p.suffix.lower() == \".csv\":\n",
    "    df = pd.read_csv(p, encoding=\"utf-8\")\n",
    "else:\n",
    "    rows = [line.rstrip(\"\\n\").split(\",\", 1) for line in p.open(\"r\", encoding=\"utf-8\")]\n",
    "    if rows and not rows[0][0].isdigit():\n",
    "        rows = rows[1:]\n",
    "    df = pd.DataFrame(rows, columns=[\"id\", \"text_no_spaces\"])\n",
    "    df[\"id\"] = df[\"id\"].astype(int)\n",
    "\n",
    "# нормализуем имена\n",
    "if \"text_no_spaces\" not in df.columns and \"text\" in df.columns:\n",
    "    df = df.rename(columns={\"text\": \"text_no_spaces\"})\n",
    "if \"id\" not in df.columns:\n",
    "    df.insert(0, \"id\", range(len(df)))\n",
    "\n",
    "df[\"predicted_positions\"] = df[\"text_no_spaces\"].apply(lambda s: predict_spaces(s, seg))\n",
    "\n",
    "out = df[[\"id\", \"text_no_spaces\", \"predicted_positions\"]]\n",
    "out.to_csv(OUTPUT_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"[cell5] head:\\n\", out.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
